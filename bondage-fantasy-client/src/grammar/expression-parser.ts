// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {highlighting} from "./expression-highlight.js"
export const parser = LRParser.deserialize({
  version: 14,
  states: "!jOVQPOOO_QPO'#C^OOQO'#Cg'#CgQOQPOOOVQPO,58xOdQPO1G.dOVQPO'#CcOlQPO7+$OOOQO7+$O7+$OOOQO,58},58}OOQO-E6a-E6aOOQO<<Gj<<Gj",
  stateData: "t~OYOS~ORPOUQO~OSSO~OTWO[UO~OTZO[UO~O",
  goto: "q[PP]PPPPbPPPhVQOSUQVTRYVQROQTSRXU",
  nodeNames: "âš  Expression Operation Operator LeftParenthesis RightParenthesis String",
  maxTerm: 12,
  propSources: [highlighting],
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: "$R~R`X^!Tpq!Trs!xxy#gyz#l|}#q!c!}#v#R#S#v#y#z!T$f$g!T#BY#BZ!T$IS$I_!T$I|$JO!T$JT$JU!T$KV$KW!T&FU&FV!T~!YYY~X^!Tpq!T#y#z!T$f$g!T#BY#BZ!T$IS$I_!T$I|$JO!T$JT$JU!T$KV$KW!T&FU&FV!T~!{TOr!xrs#[s;'S!x;'S;=`#a<%lO!x~#aOU~~#dP;=`<%l!x~#lOS~~#qOT~~#vO[~~#{QR~!c!}#v#R#S#v",
  tokenizers: [0],
  topRules: {"Expression":[0,1]},
  tokenPrec: 0
})
